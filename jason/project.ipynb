{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28eb37c1-5f14-43b5-a219-f18fa0a4013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- LIBRARY IMPORTS ----\n",
    "import pandas as pd\n",
    "import re\n",
    "frtom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfa0bc2e-c2d1-430b-921f-d96029753128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "---- RETRIEVE DATA ----\n",
    "Source:  https://www.cs.ucsb.edu/~william/data/liar_dataset.zip\n",
    "\"\"\"\n",
    "# Create column names\n",
    "column_names = ['id', 'label', 'statement', 'subjects', 'speaker', 'job_title', 'state', 'party_affiliation', 'credit_history_count',\\\n",
    "         'false_count', 'half_true_count', 'mostly_true_count', 'pants_on_fire_count', 'context']\n",
    "\n",
    "# specify data types\n",
    "dtypes = {0: 'string', 1: 'string', 2: 'string', 3: 'string', 4: 'string', 5: 'string', 6: 'string', 7: 'string',\\\n",
    "          8: 'UInt64', 9: 'UInt64', 10: 'UInt64', 11: 'UInt64', 12: 'UInt64', 13: 'string'}\n",
    "\n",
    "# Retrieve data\n",
    "statements_train_data = pd.read_csv('data/statements/train.tsv', sep='\\t', header=None, dtype=dtypes, names=column_names)\n",
    "statements_test_data = pd.read_csv('data/statements/test.tsv', sep='\\t', header=None, dtype=dtypes, names=column_names)\n",
    "statements_validate_data = pd.read_csv('data/statements/valid.tsv', sep='\\t', header=None, dtype=dtypes, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e25f09-f3ac-4af4-9024-71f998fad80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "---- CLEANING TEXT DATA ----\n",
    "The following steps will be taken to clean data\n",
    "- all non-alphabetical data will be removed\n",
    "- all text will be made lowercase\n",
    "- \n",
    "\"\"\"\n",
    "\n",
    "# Regex function to clean strings\n",
    "def regex_cleaner(text):\n",
    "    try:\n",
    "    # Make all text lowercase\n",
    "        text_lowercase = text.lower()\n",
    "    # Remove all non-alphanumeric text\n",
    "        text_alphanumeric = re.sub(r'[^a-z\\s\\-]', '', text_lowercase)\n",
    "    # Combine words that overlap to a new line\n",
    "        clean_text = re.sub(r'(\\-\\n)', '', text_alphanumeric)\n",
    "        return clean_text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "# Cleaning Statements Data\n",
    "statements_train_data['statement'] = statements_train_data['statement'].apply(regex_cleaner)\n",
    "statements_test_data['statement'] = statements_test_data['statement'].apply(regex_cleaner)\n",
    "statements_validate_data['statement'] = statements_validate_data['statement'].apply(regex_cleaner)\n",
    "\n",
    "# Clean labels\n",
    "label_dict = {'barely-true': 0, 'false': 1, 'half-true': 2, 'mostly-true': 3,\\\n",
    "              'pants-fire': 4, 'true': 5}\n",
    "label_changer = lambda ele: label_dict.get(ele)\n",
    "\n",
    "statements_train_data['label'] = statements_train_data['label'].apply(label_changer)\n",
    "statements_test_data['label'] = statements_test_data['label'].apply(label_changer)\n",
    "statements_validate_data['label'] = statements_validate_data['label'].apply(label_changer)\n",
    "\n",
    "\n",
    "# Cleaning Fake News Articles Data\n",
    "buzz_feed_fake_data = pd.read_csv('data/fake_news_articles/BuzzFeed_fake_news_content.csv')\n",
    "buzz_feed_real_data = pd.read_csv('data/fake_news_articles/BuzzFeed_real_news_content.csv')\n",
    "politi_fact_news_fake_data = pd.read_csv('data/fake_news_articles/PolitiFact_fake_news_content.csv')\n",
    "politi_fact_news_real_data = pd.read_csv('data/fake_news_articles/PolitiFact_real_news_content.csv')\n",
    "\n",
    "buzz_feed_fake_data['text'] = buzz_feed_fake_data['text'].apply(regex_cleaner)\n",
    "buzz_feed_real_data['text'] = buzz_feed_real_data['text'].apply(regex_cleaner)\n",
    "politi_fact_news_fake_data['text'] = politi_fact_news_fake_data['text'].apply(regex_cleaner)\n",
    "politi_fact_news_real_data['text'] = politi_fact_news_real_data['text'].apply(regex_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "490935f8-5b22-47ca-970e-8615350e840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONVERT DATA TO BAG OF WORDS ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35efb8d8-9d7b-4204-a0e0-aef56a5a1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccd6675c-3fa5-4836-be5b-9bc3a8bc6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = buzz_feed_real_data['text']\n",
    "vectorizer = TfidfVectorizer(strip_accents='ascii', ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1cc4473-c221-4f25-9041-7b5bd9939cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X.toarray()\n",
    "test = torch.from_numpy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b7a6804-fdf6-4344-8ea5-f78f9539fdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
